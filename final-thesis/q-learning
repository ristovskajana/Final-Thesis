import pygame
import os
from pygame.locals import *
import random
import numpy as np

pygame.init()

clock = pygame.time.Clock()
fps = 60

screen_width = 864
screen_height = 936

screen = pygame.display.set_mode((screen_width, screen_height))
pygame.display.set_caption('Flappy Bird')

# LOADING ALL IMAGES
background_img = pygame.image.load('img/bg.png')
ground_img = pygame.image.load('img/ground.png')
button_img = pygame.image.load('img/restart.png')

def draw_text(text, font, color, x, y):
    img = font.render(text, True, color)
    screen.blit(img, (x, y))

def reset_game():
    pipe_group.empty()
    flappy.rect.x = 100
    flappy.rect.y = int(screen_height/2)
    score = 0
    return score

# Number of episodes to run
num_episodes = 1000

# List to store cumulative rewards for each episode
episode_rewards = []

# Q-learning parameters
epsilon = 1.0
epsilon_decay = 0.995
epsilon_min = 0.01
alpha = 0.5
gamma = 0.99

# Discretization parameters
num_discrete_states = 10
num_discrete_velocities = 10
num_discrete_pipe_positions = 10

# Q-table initialization
num_actions = 2
q_table = np.zeros((num_discrete_states, num_discrete_velocities, num_discrete_pipe_positions + 1, num_actions))

# Initialize episode records
episode_rewards = []
episode_states = []  # Initialize episode states list
episode_actions = []

# Function to discretize a continuous value into a discrete value
def discretize(value, num_discrete_values):
    return int(value * num_discrete_values)

# Function to update Q-table based on observed reward and next state
def update_q_table(state, action, reward, next_state):
    max_q = np.max(q_table[next_state])
    q_table[state][action] += alpha * (reward + gamma * max_q - q_table[state][action])

# GAME VARIABLES
font = pygame.font.SysFont('Bauhaus 93', 60)
white = (255, 255, 255)
scroll_ground = 0
scroll_speed = 4
flying = False
dead = False
pipe_gap = 170
pipe_frequency = 1500
last_pipe = pygame.time.get_ticks() - pipe_frequency
score = 0
pass_pipe = False
last_pipe_time = pygame.time.get_ticks() 
gravity = 0.5

class Bird(pygame.sprite.Sprite):
    def __init__(self, x, y):
        pygame.sprite.Sprite.__init__(self)
        self.images = []
        self.index = 0
        self.counter = 0
        for num in range(1, 4):
            bird_img = pygame.image.load(f'img/bird{num}.png')
            self.images.append(bird_img)
        self.image = self.images[self.index]
        self.rect = self.image.get_rect()
        self.rect.center = [x, y]

        # Initialize Q-learning parameters
        self.learning_rate = 0.8
        self.discount_factor = 0.3
        self.epsilon = 0.3
        self.epsilon_decay = 0.001
        self.epsilon_min = 0.1

        # Initialize state
        self.state = None
        self.last_state = None
        self.action = None
        self.last_action = None

        # Initialize velocity
        self.vel_y = 0

    def apply_gravity(self):
        self.vel_y += gravity
        if self.vel_y > 8:
            self.vel_y = 8
        if self.rect.bottom < 768:
            self.rect.y += int(self.vel_y)


    def update(self, flying):
        self.apply_gravity()
        if flying == True:
            if self.rect.y > 768:
                dead = True
                flying = False
        else:
            if self.rect.y < 0:
                self.rect.y = 0

        # Update Q-learning state
        self.update_state()

        # Choose action
        if np.random.uniform() < self.epsilon:
            self.action = np.random.randint(num_actions)
        else:
            self.action = np.argmax(q_table[self.state])

        # Update Q-table
        def update_q_table(self, state, action, reward, next_state):
            max_q = np.max(q_table[next_state])
            q_table[state][action] += self.learning_rate * (reward + self.discount_factor * max_q - q_table[state][action])


        # Update last state and last action
        self.last_state = self.state
        self.last_action = self.action

        # Update index to animate bird
        self.counter += 1
        flap_cooldown = 5
        if self.counter > flap_cooldown:
            self.counter = 0
            self.index += 1
            if self.index >= len(self.images):
                self.index = 0
        self.image = self.images[self.index]

        # Rotate the bird
        self.image = pygame.transform.rotate(self.images[self.index], self.vel_y * -2)
        self.rect = self.image.get_rect(center=(self.rect.centerx, self.rect.centery))


    def jump(self):
        self.vel_y = -10

    def not_jump(self):
        self.vel_y = +0.5

    def update_state(self):
        # Discretize position, velocity, and pipe position
        discrete_pos = discretize(self.rect.y / screen_height, num_discrete_states)
        discrete_vel = discretize(self.vel_y / 10, num_discrete_velocities)
        pipe_pos = self.get_closest_pipe_position()
        discrete_pipe_pos = discretize(pipe_pos / screen_width, num_discrete_pipe_positions)

        # Combine state variables into a tuple
        self.state = (discrete_pos, discrete_vel, discrete_pipe_pos)

    def get_closest_pipe_position(self):
        closest_pipe_pos = screen_width
        for pipe in pipe_group:
            if pipe.rect.x > self.rect.centerx:
                closest_pipe_pos = min(closest_pipe_pos, pipe.rect.x)
        return closest_pipe_pos
    
    def choose_action(self):
        if np.random.uniform() < self.epsilon:
            return np.random.randint(num_actions)
        else:
            return np.argmax(q_table[self.state])

    def update_q_table(self, state, action, reward, next_state):
        max_q = np.max(q_table[next_state])
        q_table[state][action] += self.learning_rate * (reward + self.discount_factor * max_q - q_table[state][action])

        
# Creating bird class
bird_group = pygame.sprite.Group()
flappy = Bird(100, int(screen_height/2))
bird_group.add(flappy)

class Pipe(pygame.sprite.Sprite):
    def __init__(self, x, y, position):
        pygame.sprite.Sprite.__init__(self)
        self.image = pygame.image.load('img/pipe.png')
        self.rect = self.image.get_rect()
        self.passed = False  # Initialize the 'passed' attribute to False
        # position variable determines if the pipe is coming from the bottom or top

        if position == 1:
            self.image = pygame.transform.flip(self.image, False, True)
            self.rect.bottomleft = [x, y - int(pipe_gap/2)]
        if position == -1:
            self.rect.topleft = [x, y + int(pipe_gap/2)]

    def update(self):
        self.rect.x -= scroll_speed
        if self.rect.right < 0:
            self.kill()

# Create pipe group
pipe_group = pygame.sprite.Group()

# Load Q-table if it exists
q_table = np.load('q_table.npy') if os.path.isfile('q_table.npy') else q_table

run = True
while run:
    clock.tick(fps)
    screen.blit(background_img, (0, 0))

    # Update and draw pipes
    pipe_group.draw(screen)
    pipe_group.update()

    # Draw ground
    scroll_ground -= scroll_speed
    if abs(scroll_ground) > 35:
        scroll_ground = 0
    screen.blit(ground_img, (scroll_ground, 768))

    # Draw and update birds
    bird_group.draw(screen)
    bird_group.update(flying)

    current_time = pygame.time.get_ticks()
    if current_time - last_pipe >= pipe_frequency:
        pipe_x = screen_width
        pipe_y = random.randint(300, 600)  # Adjust the range as needed
        top_pipe = Pipe(pipe_x, pipe_y, -1)
        bottom_pipe = Pipe(pipe_x, pipe_y, 1)
        pipe_group.add(top_pipe, bottom_pipe)
        last_pipe = current_time

    # Check collision with pipes
    if pygame.sprite.groupcollide(bird_group, pipe_group, False, False):
        dead = True

    if not dead:
        # Check if bird has passed the pipe
        for pipe in pipe_group:
            if pipe.rect.right < flappy.rect.left and not pipe.passed:
                pipe.passed = True
                pass_pipe = True

        # Update score
        if pass_pipe:
            score += 1
            pass_pipe = False

        # Update Q-learning state and choose action
        flappy.update_state()
        action = flappy.choose_action()

        # Apply action
        if action == 1:
            flying = True
            flappy.jump()
        else:
            flying = False
            flappy.not_jump()

        # Choose action
        flappy.last_action = action
        flappy.action = action

        # Update Q-table
        if flappy.last_state is not None and flappy.last_action is not None:
            reward = 10 if pass_pipe else -1000  # Assign reward based on passing the pipe or hitting an obstacle
            next_state = flappy.state  # Update next state
            flappy.update_q_table(flappy.last_state, flappy.last_action, reward, next_state)  # Update the Q-table using the flappy object

        # Rest of the code...


        # Update last state and last action
        flappy.last_state = flappy.state

        # Draw score
        draw_text(str(score), font, white, int(screen_width / 2), 20)

    # Check if the bird has hit the ground
    if flappy.rect.y > 768 or dead:
        dead = False
        flying = False
        episode_rewards.append(score)
        print("Q-table:")
        print(q_table)  # Print the Q-table
        score = reset_game()

        # Decay epsilon
        if epsilon > epsilon_min:
            epsilon *= epsilon_decay

        # Update Q-table using episode rewards
        for i in range(len(episode_rewards) - 1, -1, -1):
            reward = episode_rewards[i]
            state = episode_states[i]
            action = episode_actions[i]
            next_state = episode_states[i + 1] if i + 1 < len(episode_states) else None
            if next_state is not None:
                flappy.update_q_table(flappy.last_state, flappy.last_action, reward, next_state)  # Update the Q-table using the flappy object

        # Clear episode records
        episode_rewards = []
        episode_states = []
        episode_actions = []

        # Save the Q-table after each episode
        np.save('q_table.npy', q_table)

        # Load Q-table for the next episode
        q_table = np.load('q_table.npy')


    # Append current state and action to episode records
    episode_states.append(flappy.state)
    episode_actions.append(action)


    pygame.display.update()

pygame.quit()
